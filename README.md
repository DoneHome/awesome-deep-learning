
# Awesome Deep Learning Resources: [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

A curated list of awesome deep learning resources, inspired by [awesome-computer-vision](https://github.com/jbhuang0604/awesome-computer-vision).

## Table of Contents

 - [Blogs](#blogs)
 - [Papers](#papers)
 - [Videos](#videos)
 - [Books](#Books)
 - [Slides](#Slides)

## Blogs
 * [An overview of gradient descent optimization algorithms](http://sebastianruder.com/optimizing-gradient-descent/index.html#challenges), a PhD student.

## Papers
 * [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167), Sergey Ioffe, Christian Szegedy.
 * [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf), Nitish Srivastava, Geoffrey Hinton, et al.
 * [Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour](https://arxiv.org/abs/1706.02677), facebook researchers.
 * [Practical Recommendations for Gradient-Based Training of Deep Architectures](https://arxiv.org/abs/1206.5533), Yoshua Bengio.
 * [Coursera.org-Deep learning](https://www.coursera.org/specializations/deep-learning), Andrew Ng.

## Videos
 * [CS231n: Convolutional Neural Networks for Visual Recognition](http://vision.stanford.edu/teaching/cs231n/syllabus.html), Andrej Karpathy.
 * [Machine Learning and having it Deep and Structured](http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS17.html),Hung-yi Lee.

## Books
 * [Deep Learning](http://www.deeplearningbook.org/), Ian Goodfellow et al.

## Slides
 * [Overview of mini-batch gradient descent](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf), Geoffrey Hinton et al.

## Licenses
License

[![CC0](http://i.creativecommons.org/p/zero/1.0/88x31.png)](http://creativecommons.org/publicdomain/zero/1.0/)

To the extent possible under law, [DoneHome](https://github.com/DoneHome) and [superAsir](https://github.com/JoeAsir) has waived all copyright and related or neighboring rights to this work.
